import tensorflow as tf
from tensorflow import keras
import os
import numpy as np
import matplotlib.pyplot as plt
from keras_preprocessing.image import ImageDataGenerator
from keras import layers
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, BatchNormalization, Activation, ZeroPadding2D
from keras.layers import UpSampling2D, Conv2DTranspose, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam


# Define the data directories
dir_A = r"C:\Users\NIKITAA\Downloads\toutput(3)\toutput"
dir_B = r"C:\Users\NIKITAA\Downloads\tinput(5)\tinput"

# Define the image dimensions
img_rows = 256
img_cols = 256
channels = 3
img_shape = (img_rows, img_cols, channels)

# Define the batch size
batch_size = 1

# Define the ImageDataGenerator for folder tinput
datagen_tinput = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1
)

# Define the ImageDataGenerator for folder toutput
datagen_toutput = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1
)

# Load the images from folder tinput and preprocess them
train_generator_tinput = datagen_tinput.flow_from_directory(
    directory=dir_tinput,
    target_size=(img_rows, img_cols),
    batch_size=batch_size,
    class_mode=None,
    subset='training',
    shuffle=True,
    seed=42
)

# Load the images from folder toutput and preprocess them
train_generator_toutput = datagen_toutput.flow_from_directory(
    directory=dir_toutput,
    target_size=(img_rows, img_cols),
    batch_size=batch_size,
    class_mode=None,
    subset='training',
    shuffle=True,
    seed=42
)

# Load the validation images from folder tinput and preprocess them
val_generator_tinput = datagen_tinput.flow_from_directory(
    directory=dir_tinput,
    target_size=(img_rows, img_cols),
    batch_size=batch_size,
    class_mode=None,
    subset='validation',
    shuffle=False,
    seed=42
)

# Load the validation images from folder toutput and preprocess them
val_generator_toutput = datagen_toutput.flow_from_directory(
    directory=dir_toutput,
    target_size=(img_rows, img_cols),
    batch_size=batch_size,
    class_mode=None,
    subset='validation',
    shuffle=False,
    seed=42
)

def build_discriminator():

    # Image input
    d_input = Input(shape=img_shape)

    # Label input
    label_input = Input(shape=(1,))

    # Concatenate image and label
    concat_input = Concatenate()([d_input, label_input])

    # Convolutional layers
    d = Conv2D(64, kernel_size=4, strides=2, padding='same')(


concat_input)
d = LeakyReLU(alpha=0.2)(d)

d = Conv2D(128, kernel_size=4, strides=2, padding='same')(d)
d = BatchNormalization()(d)
d = LeakyReLU(alpha=0.2)(d)

d = Conv2D(256, kernel_size=4, strides=2, padding='same')(d)
d = BatchNormalization()(d)
d = LeakyReLU(alpha=0.2)(d)

d = Conv2D(512, kernel_size=4, strides=2, padding='same')(d)
d = BatchNormalization()(d)
d = LeakyReLU(alpha=0.2)(d)

d = Conv2D(1, kernel_size=4, strides=1, padding='same')(d)

# Output
validity = Activation('sigmoid')(d)

# Model definition
discriminator = Model([d_input, label_input], validity)

return discriminator

def build_generator():

# Source image input
s_input = Input(shape=img_shape)

# Encoder
e1 = Conv2D(64, kernel_size=4, strides=2, padding='same')(s_input)
e1 = LeakyReLU(alpha=0.2)(e1)

e2 = Conv2D(128, kernel_size=4, strides=2, padding='same')(e1)
e2 = BatchNormalization()(e2)
e2 = LeakyReLU(alpha=0.2)(e2)

e3 = Conv2D(256, kernel_size=4, strides=2, padding='same')(e2)
e3 = BatchNormalization()(e3)
e3 = LeakyReLU(alpha=0.2)(e3)

e4 = Conv2D(512, kernel_size=4, strides=2, padding='same')(e3)
e4 = BatchNormalization()(e4)
e4 = LeakyReLU(alpha=0.2)(e4)

e5 = Conv2D(512, kernel_size=4, strides=2, padding='same')(e4)
e5 = BatchNormalization()(e5)
e5 = LeakyReLU(alpha=0.2)(e5)

e6 = Conv2D(512, kernel_size=4, strides=2, padding='same')(e5)
e6 = BatchNormalization()(e6)
e6 = LeakyReLU(alpha=0.2)(e6)

e7 = Conv2D(512, kernel_size=4, strides=2, padding='same')(e6)
e7 = BatchNormalization()(e7)
e7 = LeakyReLU(alpha=0.2)(e7)

e8 = Conv2D(512, kernel_size=4, strides=2, padding='same')(e7)
e8 = BatchNormalization()(e8)
e8 = LeakyReLU(alpha=0.2)(e8)

# Decoder
d1 = Conv2DTranspose(512, kernel_size=4, strides=2, padding='same')(e8)
d1 = BatchNormalization()(d1)
d1 = Dropout(0.5)(d1)
d1 = Concatenate()([d1, e7])
d1 = Activation('relu')(d1)

d2= Conv2DTranspose(512, kernel_size=4, strides=2, padding='same')(d1)
d2 = BatchNormalization()(d2)
d2 = Dropout(0.5)(d2)
d2 = Concatenate()([d2, e6])
d2 = Activation('relu')(d2)

d3 = Conv2DTranspose(512, kernel_size=4, strides=2, padding='same')(d2)
d3 = BatchNormalization()(d3)
d3 = Dropout(0.5)(d3)
d3 = Concatenate()([d3, e5])
d3 = Activation('relu')(d3)

d4 = Conv2DTranspose(512, kernel_size=4, strides=2, padding='same')(d3)
d4 = BatchNormalization()(d4)
d4 = Concatenate()([d4, e4])
d4 = Activation('relu')(d4)

d5 = Conv2DTranspose(256, kernel_size=4, strides=2, padding='same')(d4)
d5 = BatchNormalization()(d5)
d5 = Concatenate()([d5, e3])
d5 = Activation('relu')(d5)

d6 = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(d5)
d6 = BatchNormalization()(d6)
d6 = Concatenate()([d6, e2])
d6 = Activation('relu')(d6)

d7 = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(d6)
d7 = BatchNormalization()(d7)
d7 = Concatenate()([d7, e1])
d7 = Activation('relu')(d7)

# Output
g_output = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(d7)

# Model definition
generator = Model(s_input, g_output)

return generator

discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy',
optimizer=Adam(lr=0.0002, beta_1=0.5),
metrics=['accuracy'])

generator = build_generator()

source_img = Input(shape=img_shape)
generated_img = generator(source_img)

discriminator.trainable = False

validity = discriminator([generated_img, source_img])

combined = Model(source_img, validity)
combined.compile(loss='binary_crossentropy',
optimizer=Adam(lr=0.0002, beta_1=0.5))

def train(epochs, batch_size, sample_interval):

# Load the dataset
X_train, y_train = load_data()

#
# Rescale -1 to 1
X_train = X_train / 127.5 - 1.
y_train = y_train / 127.5 - 1.

# Adversarial ground truths
valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))

for epoch in range(epochs):

    # ---------------------
    #  Train Discriminator
    # ---------------------

    # Select a random half of images
    idx = np.random.randint(0, X_train.shape[0], batch_size)
    imgs = X_train[idx]
    targets = y_train[idx]

    # Generate a half of new images
    gen_imgs = generator.predict(imgs)

    # Train the discriminator
    d_loss_real = discriminator.train_on_batch([targets, imgs], valid)
    d_loss_fake = discriminator.train_on_batch([gen_imgs, imgs], fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # ---------------------
    #  Train Generator
    # ---------------------

    # Select a random half of images
    idx = np.random.randint(0, X_train.shape[0], batch_size)
    imgs = X_train[idx]

    # Train the generator
    g_loss = combined.train_on_batch(imgs, valid)

    # Plot the progress
    print("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

    # If at save interval
    if epoch % sample_interval == 0:
        # Select a random half of images
        idx = np.random.randint(0, X_train.shape[0], 6)
        imgs = X_train[idx]
        targets = y_train[idx]

        # Generate a half of new images
        gen_imgs = generator.predict(imgs)

        # Rescale images 0 - 1
        gen_imgs = 0.5 * gen_imgs + 0.5

        # Plot the results
        fig, axs = plt.subplots(2, 3)
        cnt = 0
        for i in range(2):
            for j in range(3):
                axs[i,j].imshow(gen_imgs[cnt, :,:,:])
                axs[i,j].axis('off')
                cnt += 1
        fig.savefig("images/%d.png" % epoch)
        plt.close()
train(epochs=200, batch_size=16, sample_interval=20)

X_test, y_test = load_test_data()

X_test = X_test / 127.5 - 1.
y_test = y_test / 127.5 - 1.

y_pred = generator.predict(X_test)

mse = np.mean(np.square(y_pred - y_test))
print("Mean Squared Error: ", mse)

fig, axs = plt.subplots(2, 5)
cnt = 0
for i in range(2):
for j in range(5):
axs[i,j].imshow(y_pred[cnt, :,:,:])
axs[i,j].axis('off')
cnt += 1
fig.savefig("images/test_results.png")
plt.show()




