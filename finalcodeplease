!pip install tensorflow-gpu==2.6.0
!pip install tensorflow_datasets
import tensorflow as tf
import tensorflow_datasets as tfds
import os
import numpy as np
import matplotlib.pyplot as plt

AUTOTUNE = tf.data.AUTOTUNE

tinput_path = "C:\\Users\\NIKITAA\\Downloads\\tinput(5)\\tinput\\"
toutput_path = "C:\\Users\\NIKITAA\\Downloads\\toutput(3)\\toutput\\"

tinput_files = tf.data.Dataset.list_files(tinput_path + "*.jpg")
toutput_files = tf.data.Dataset.list_files(toutput_path + "*.jpg")

def parse_image(filename):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.cast(image, tf.float32)
    image = (image / 127.5) - 1.0
    return image

def random_crop(image):
    cropped_image = tf.image.random_crop(image, size=[256, 256, 3])
    return cropped_image

def preprocess_image(image):
    cropped_image = random_crop(image)
    cropped_image = tf.image.random_flip_left_right(cropped_image)
    return cropped_image

tinput_dataset = tinput_files.map(parse_image, num_parallel_calls=AUTOTUNE)
toutput_dataset = toutput_files.map(parse_image, num_parallel_calls=AUTOTUNE)

train_size = int(0.9 * 6000)
val_size = 6000 - train_size

train_tinput_dataset = tinput_dataset.take(train_size).map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(buffer_size=1000).batch(1)
train_toutput_dataset = toutput_dataset.take(train_size).map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(buffer_size=1000).batch(1)

val_tinput_dataset = tinput_dataset.skip(train_size).batch(1)
val_toutput_dataset = toutput_dataset.skip(train_size).batch(1)

def generator():
    inputs = tf.keras.layers.Input(shape=[256,256,3])
    
    down1 = downsample(inputs, 64, apply_batchnorm=False)
    down2 = downsample(down1, 128)
    down3 = downsample(down2, 256)
    down4 = downsample(down3, 512)
    down5 = downsample(down4, 512)
    down6 = downsample(down5, 512)
    down7 = downsample(down6, 512)
    down8 = downsample(down7, 512)
    
    up1 = upsample(down8, 512)
    up2 = upsample(tf.keras.layers.concatenate([up1, down7]), 512)
    up3 = upsample(tf.keras.layers.concatenate([up2, down6]), 512)
    up4 = upsample(tf.keras.layers.concatenate([up3, down5]), 512)
    up5 = upsample(tf.keras.layers.concatenate([up4, down4]), 256)
    up6 = upsample(tf.keras.layers.concatenate([up5, down3]), 128)
    up7 = upsample(tf.keras.layers.concatenate([up6, down2]), 64)

    outputs = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(4,4), strides=2, padding='same', activation='tanh')(tf.keras.layers.concatenate([up7, down1]))

    return tf.keras.Model(inputs=inputs, outputs=outputs)
  
 def discriminator():
    inputs = tf.keras.layers.Input(shape=[256,256,6])
    down1 = downsample(inputs, 64, apply_batchnorm=False)
    down2 = downsample(down1, 128)
    down3 = downsample(down2, 256)

    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)
    conv = tf.keras.layers.Conv2D(filters=512, kernel_size=(4,4), strides=1, padding='valid', use_bias=False)(zero_pad1)
    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)
    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)
    outputs = tf.keras.layers.Conv2D(filters=1, kernel_size=(4,4), strides=1, padding='valid')(zero_pad2)

    return tf.keras.Model(inputs=inputs, outputs=outputs)
    
 loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

 def discriminator_loss(real_output, generated_output):
    real_loss = loss_object(tf.ones_like(real_output), real_output)
    generated_loss = loss_object(tf.zeros_like(generated_output), generated_output)
    total_loss = real_loss + generated_loss
    return total_loss

 def generator_loss(generated_output, target_output, generated_image):
    gan_loss = loss_object(tf.ones_like(generated_output), generated_output)
    l1_loss = tf.reduce_mean(tf.abs(target_output - generated_image))
    total_loss = gan_loss + (100 * l1_loss)
    return total_loss
 generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
 discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
 
 def generate_images(model, test_input):
    prediction = model(test_input, training=True)
    return prediction[0]
  
 @tf.function
 def train_step(input_image, target_image):
 with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
 generated_image = generator(input_image, training=True)
 real_output = discriminator(tf.concat([input_image, target_image], axis=3), training=True)
 generated_output = discriminator(tf.concat([input_image, generated_image], axis=3), training=True)
 
 gen_loss = generator_loss(generated_output, target_image, generated_image)
 disc_loss = discriminator_loss(real_output, generated_output)

 generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)
 discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

 generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
 discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

 return gen_loss, disc_loss
 
 import os
 import time
 from IPython.display import clear_output

 def fit(train_input, train_output, epochs, test_input, test_output, batch_size=1, save_every=10):
 checkpoint_dir = './training_checkpoints'
 checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
 checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
 discriminator_optimizer=discriminator_optimizer,
 generator=generator,
 discriminator=discriminator)
 
 for epoch in range(epochs):
    start = time.time()

    for i in range(0, len(train_input), batch_size):
        input_image_batch = train_input[i:i+batch_size]
        target_image_batch = train_output[i:i+batch_size]

        gen_loss, disc_loss = train_step(input_image_batch, target_image_batch)

    if (epoch + 1) % save_every == 0:
        clear_output(wait=True)
        for j in range(5):
            generated_image = generate_images(generator, tf.expand_dims(test_input[j], 0))
            plt.imshow(generated_image)
            plt.show()

        checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time taken for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

clear_output(wait=True)
for j in range(5):
    generated_image = generate_images(generator, tf.expand_dims(test_input[j], 0))
    plt.imshow(generated_image)
    plt.show()

checkpoint.save(file_prefix = checkpoint_prefix)

import os
import cv2
import numpy as np

input_folder = r"C:\Users\NIKITAA\Downloads\tinput(5)\tinput"
output_folder = r"C:\Users\NIKITAA\Downloads\toutput(3)\toutput"

input_files = os.listdir(input_folder)[:5400]
output_files = os.listdir(output_folder)[:5400]

train_input = []
train_output = []

for i in range(len(input_files)):
input_image = cv2.imread(os.path.join(input_folder, input_files[i]))
output_image = cv2.imread(os.path.join(output_folder, output_files[i]))

input_image = cv2.resize(input_image, (256, 256)) / 255.0
output_image = cv2.resize(output_image, (256, 256)) / 255.0

train_input.append(input_image)
train_output.append(output_image)

test_input = []
test_output = []

input_files = os.listdir(input_folder)[5400:]
output_files = os.listdir(output_folder)[5400:]

for i in range(len(input_files)):
input_image = cv2.imread(os.path.join(input_folder, input_files[test_input, test_output] = [np.array(test_input), np.array(test_output)]

print("Training input shape:", train_input.shape)
print("Training output shape:", train_output.shape)
print("Testing input shape:", test_input.shape)
print("Testing output shape:", test_output.shape)

EPOCHS = 50
BATCH_SIZE = 1

fit(train_input, train_output, EPOCHS, test_input, test_output, BATCH_SIZE, save_every=10)

checkpoint_dir = './training_checkpoints'
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
discriminator_optimizer=discriminator_optimizer,
generator=generator,
discriminator=discriminator)
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

input_image = cv2.imread("<path-to-input-image>")
input_image = cv2.resize(input_image, (256, 256)) / 255.0
input_image = np.expand_dims(input_image, axis=0)
output_image = generate_images(generator, input_image)

plt.imshow(output_image[0])
plt.show()






















    




